{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLf3EXaQkPcCjfbFTRchsZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nitinsen001/CodeAlpha-Credit-Scoring-Model/blob/main/Credit_Scoring_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yznzd0n-cwKO",
        "outputId": "6a074008-e712-4bbc-8a1a-c08dfc93c262"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.12/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2025.8.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "# 1. Dataset Load\n",
        "statlog = fetch_ucirepo(id=144)  # German Credit Data\n",
        "X = statlog.data.features\n",
        "y = statlog.data.targets  # Labels: 1 = good, 2 = bad\n",
        "\n",
        "# Map to 0/1\n",
        "y = y.replace({1: 1, 2: 0})\n",
        "\n",
        "# 2. EDA (quick look)\n",
        "print(X.head())\n",
        "print(X.info())\n",
        "print(y.value_counts())\n",
        "\n",
        "# 3. Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 4. Preprocessing: Identify categorical and numerical features, then apply transformations\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n",
        "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "# 5. Train Models using Pipelines\n",
        "# Logistic Regression Pipeline\n",
        "log_reg_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                   ('classifier', LogisticRegression(class_weight=\"balanced\", max_iter=1000))])\n",
        "\n",
        "log_reg_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Random Forest Pipeline\n",
        "rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                             ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))])\n",
        "\n",
        "rf_pipeline.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# 6. Evaluate Models\n",
        "for name, model in [\n",
        "    (\"Logistic Regression\", log_reg_pipeline),\n",
        "    (\"Random Forest\", rf_pipeline)\n",
        "]:\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "    print(f\"\\n{name} Results:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n",
        "\n",
        "# 7. Make simplified predictions (using Random Forest as an example)\n",
        "predictions = rf_pipeline.predict(X_test)\n",
        "\n",
        "# Map predictions to \"Creditworthy\" or \"Not Creditworthy\"\n",
        "simplified_predictions = [\"Creditworthy\" if pred == 1 else \"Not Creditworthy\" for pred in predictions]\n",
        "\n",
        "print(\"\\nSimplified Predictions on Test Data (using Random Forest):\")\n",
        "for i, prediction in enumerate(simplified_predictions[:10]): # Print first 10 for brevity\n",
        "    print(f\"Sample {i+1}: {prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Da_vXshce9v",
        "outputId": "0401e03f-9ebc-4901-8a3f-b8ebd5cc2475"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Attribute1  Attribute2 Attribute3 Attribute4  Attribute5 Attribute6  \\\n",
            "0        A11           6        A34        A43        1169        A65   \n",
            "1        A12          48        A32        A43        5951        A61   \n",
            "2        A14          12        A34        A46        2096        A61   \n",
            "3        A11          42        A32        A42        7882        A61   \n",
            "4        A11          24        A33        A40        4870        A61   \n",
            "\n",
            "  Attribute7  Attribute8 Attribute9 Attribute10  Attribute11 Attribute12  \\\n",
            "0        A75           4        A93        A101            4        A121   \n",
            "1        A73           2        A92        A101            2        A121   \n",
            "2        A74           2        A93        A101            3        A121   \n",
            "3        A74           2        A93        A103            4        A122   \n",
            "4        A73           3        A93        A101            4        A124   \n",
            "\n",
            "   Attribute13 Attribute14 Attribute15  Attribute16 Attribute17  Attribute18  \\\n",
            "0           67        A143        A152            2        A173            1   \n",
            "1           22        A143        A152            1        A173            1   \n",
            "2           49        A143        A152            1        A172            2   \n",
            "3           45        A143        A153            1        A173            2   \n",
            "4           53        A143        A153            2        A173            2   \n",
            "\n",
            "  Attribute19 Attribute20  \n",
            "0        A192        A201  \n",
            "1        A191        A201  \n",
            "2        A191        A201  \n",
            "3        A191        A201  \n",
            "4        A191        A201  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 20 columns):\n",
            " #   Column       Non-Null Count  Dtype \n",
            "---  ------       --------------  ----- \n",
            " 0   Attribute1   1000 non-null   object\n",
            " 1   Attribute2   1000 non-null   int64 \n",
            " 2   Attribute3   1000 non-null   object\n",
            " 3   Attribute4   1000 non-null   object\n",
            " 4   Attribute5   1000 non-null   int64 \n",
            " 5   Attribute6   1000 non-null   object\n",
            " 6   Attribute7   1000 non-null   object\n",
            " 7   Attribute8   1000 non-null   int64 \n",
            " 8   Attribute9   1000 non-null   object\n",
            " 9   Attribute10  1000 non-null   object\n",
            " 10  Attribute11  1000 non-null   int64 \n",
            " 11  Attribute12  1000 non-null   object\n",
            " 12  Attribute13  1000 non-null   int64 \n",
            " 13  Attribute14  1000 non-null   object\n",
            " 14  Attribute15  1000 non-null   object\n",
            " 15  Attribute16  1000 non-null   int64 \n",
            " 16  Attribute17  1000 non-null   object\n",
            " 17  Attribute18  1000 non-null   int64 \n",
            " 18  Attribute19  1000 non-null   object\n",
            " 19  Attribute20  1000 non-null   object\n",
            "dtypes: int64(7), object(13)\n",
            "memory usage: 156.4+ KB\n",
            "None\n",
            "class\n",
            "1        700\n",
            "0        300\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.69      0.60        90\n",
            "           1       0.85      0.73      0.79       210\n",
            "\n",
            "    accuracy                           0.72       300\n",
            "   macro avg       0.69      0.71      0.69       300\n",
            "weighted avg       0.75      0.72      0.73       300\n",
            "\n",
            "ROC-AUC: 0.777883597883598\n",
            "\n",
            "Random Forest Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.37      0.47        90\n",
            "           1       0.77      0.92      0.84       210\n",
            "\n",
            "    accuracy                           0.75       300\n",
            "   macro avg       0.72      0.64      0.66       300\n",
            "weighted avg       0.74      0.75      0.73       300\n",
            "\n",
            "ROC-AUC: 0.7633597883597883\n",
            "\n",
            "Simplified Predictions on Test Data (using Random Forest):\n",
            "Sample 1: Creditworthy\n",
            "Sample 2: Not Creditworthy\n",
            "Sample 3: Creditworthy\n",
            "Sample 4: Creditworthy\n",
            "Sample 5: Creditworthy\n",
            "Sample 6: Creditworthy\n",
            "Sample 7: Creditworthy\n",
            "Sample 8: Creditworthy\n",
            "Sample 9: Creditworthy\n",
            "Sample 10: Not Creditworthy\n"
          ]
        }
      ]
    }
  ]
}